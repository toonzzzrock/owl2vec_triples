{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python -u OWL2Vec_Plus.py --walker wl --walk_depth 4 --URI_Doc yes --Lit_Doc yes --Embed_Out_URI no --Embed_Out_Words yes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import multiprocessing\n",
    "import gensim\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from nltk import word_tokenize\n",
    "from owl2vec_star.lib.Evaluator import Evaluator\n",
    "from owl2vec_star.lib.RDF2Vec_Embed import get_rdf2vec_walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttributeDict(dict):\n",
    "    def __getattr__(self, attr):\n",
    "        return self[attr]\n",
    "\n",
    "    def __setattr__(self, attr, value):\n",
    "        self[attr] = value\n",
    "\n",
    "# Usage\n",
    "FLAGS = AttributeDict()\n",
    "FLAGS['onto_file'] = \"files/foodon-merged.train.owl\"\n",
    "FLAGS['train_file'] = \"files/train.csv\"\n",
    "FLAGS['valid_file'] = \"files/valid.csv\"\n",
    "FLAGS['test_file'] = \"files/test.csv\"\n",
    "FLAGS['class_file'] = \"files/classes.txt\"\n",
    "FLAGS['inferred_ancestor_file'] = \"files/inferred_ancestors.txt\"\n",
    "FLAGS[\"embedsize\"] = 100\n",
    "\n",
    "FLAGS[\"URI_Doc\"] =\"yes\"\n",
    "FLAGS[\"Lit_Doc\"] =\"no\"\n",
    "FLAGS[\"Mix_Doc\"] =\"no\"\n",
    "FLAGS[\"Mix_Type\"] =\"random\"\n",
    "FLAGS[\"Embed_Out_URI\"] =\"yes\"\n",
    "FLAGS[\"Embed_Out_Words\"] =\"yes\"\n",
    "\n",
    "FLAGS[\"input_type\"] =\"concatenate\"\n",
    "FLAGS[\"walk_depth\"] = 4\n",
    "FLAGS[\"walker\"] =\"wl\"\n",
    "FLAGS[\"axiom_file\"] ='files/axioms.txt'\n",
    "FLAGS[\"annotation_file\"] ='files/annotations.txt'\n",
    "\n",
    "classes = [line.strip() for line in open(FLAGS.class_file).readlines()]\n",
    "candidate_num = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def URI_parse(uri):\n",
    "    \"\"\"Parse a URI: remove the prefix, parse the name part (Camel cases are plit)\"\"\"\n",
    "    uri = re.sub(\"http[a-zA-Z0-9:/._-]+#\", \"\", uri)\n",
    "    uri = uri.replace('_', ' ').replace('-', ' ').replace('.', ' ').replace('/', ' '). \\\n",
    "        replace('\"', ' ').replace(\"'\", ' ')\n",
    "    words = []\n",
    "    for item in uri.split():\n",
    "        matches = re.finditer('.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)', item)\n",
    "        for m in matches:\n",
    "            word = m.group(0)\n",
    "            if word.isalpha():\n",
    "                words.append(word.lower())\n",
    "    return words\n",
    "\n",
    "\n",
    "def embed(model, instances):\n",
    "\n",
    "    def word_embeding(inst):\n",
    "        v = np.zeros(model.vector_size)\n",
    "        if inst in uri_label:\n",
    "            words = uri_label.get(inst)\n",
    "            n = 0\n",
    "            for word in words:\n",
    "                if word in model.wv.index_to_key:\n",
    "                    v += model.wv.get_vector(word)\n",
    "                    n += 1\n",
    "            return v / n if n > 0 else v\n",
    "        else:\n",
    "            return v\n",
    "\n",
    "    feature_vectors = []\n",
    "    for instance in instances:\n",
    "        if FLAGS.Embed_Out_Words.lower() == 'yes' and FLAGS.Embed_Out_URI.lower() == 'yes':\n",
    "            v_uri = model.wv.get_vector(instance) if instance in model.wv.index_to_key else np.zeros(model.vector_size)\n",
    "            v_word = word_embeding(inst=instance)\n",
    "            feature_vectors.append(np.concatenate((v_uri, v_word)))\n",
    "\n",
    "        elif FLAGS.Embed_Out_Words.lower() == 'no' and FLAGS.Embed_Out_URI.lower() == 'yes':\n",
    "            v_uri = model.wv.get_vector(instance) if instance in model.wv.index_to_key else np.zeros(model.vector_size)\n",
    "            feature_vectors.append(v_uri)\n",
    "\n",
    "        elif FLAGS.Embed_Out_Words.lower() == 'yes' and FLAGS.Embed_Out_URI.lower() == 'no':\n",
    "            v_word = word_embeding(inst=instance)\n",
    "            feature_vectors.append(v_word)\n",
    "\n",
    "        else:\n",
    "            print(\"Unknown embed out type\")\n",
    "            sys.exit(0)\n",
    "\n",
    "    return feature_vectors\n",
    "\n",
    "\n",
    "def pre_process_words(words):\n",
    "    text = ' '.join([re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', word, flags=re.MULTILINE) for word in words])\n",
    "    tokens = word_tokenize(text)\n",
    "    processed_tokens = [token.lower() for token in tokens if token.isalpha()]\n",
    "    return processed_tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract corpus and learning embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "uri_label = dict()\n",
    "annotations = list()\n",
    "for line in open(FLAGS.annotation_file, encoding=\"utf8\").readlines():\n",
    "    tmp = line.strip().split()\n",
    "    if tmp[1] == 'http://www.w3.org/2000/01/rdf-schema#label':\n",
    "        uri_label[tmp[0]] = pre_process_words(tmp[2:])\n",
    "    elif tmp[0] in classes:\n",
    "        annotations.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 2218855 walks for 28182 classes!\n",
      "Extracted 34184 axiom sentences\n"
     ]
    }
   ],
   "source": [
    "\n",
    "walk_sentences, axiom_sentences = list(), list()\n",
    "if FLAGS.URI_Doc.lower() == 'yes':\n",
    "    walks_ = get_rdf2vec_walks(onto_file=FLAGS.onto_file, walker_type=FLAGS.walker,\n",
    "                               walk_depth=FLAGS.walk_depth, classes=classes)\n",
    "    print('Extracted {} walks for {} classes!'.format(len(walks_), len(classes)))\n",
    "    walk_sentences += [list(map(str, x)) for x in walks_]\n",
    "    for line in open(FLAGS.axiom_file).readlines():\n",
    "        axiom_sentence = [item for item in line.strip().split()]\n",
    "        axiom_sentences.append(axiom_sentence)\n",
    "    print('Extracted %d axiom sentences' % len(axiom_sentences))\n",
    "URI_Doc = walk_sentences + axiom_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lit_Doc = list()\n",
    "if FLAGS.Lit_Doc.lower() == 'yes':\n",
    "    for annotation in annotations:\n",
    "        processed_words = pre_process_words(annotation[2:])\n",
    "        if len(processed_words) > 0:\n",
    "            Lit_Doc.append(uri_label[annotation[0]] + processed_words)\n",
    "    print('Extracted %d literal annotations' % len(Lit_Doc))\n",
    "\n",
    "    for sentence in walk_sentences:\n",
    "        lit_sentence = list()\n",
    "        for item in sentence:\n",
    "            if item in uri_label:\n",
    "                lit_sentence += uri_label[item]\n",
    "            elif item.startswith('http://www.w3.org'):\n",
    "                lit_sentence += [item.split('#')[1].lower()]\n",
    "            else:\n",
    "                lit_sentence += [item]\n",
    "        Lit_Doc.append(lit_sentence)\n",
    "\n",
    "    for sentence in axiom_sentences:\n",
    "        lit_sentence = list()\n",
    "        for item in sentence:\n",
    "            lit_sentence += uri_label[item] if item in uri_label else [item.lower()]\n",
    "        Lit_Doc.append(lit_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Mix_Doc = list()\n",
    "if FLAGS.Mix_Doc.lower() == 'yes':\n",
    "    for sentence in walk_sentences:\n",
    "        if FLAGS.Mix_Type.lower() == 'all':\n",
    "            for index in range(len(sentence)):\n",
    "                mix_sentence = list()\n",
    "                for i, item in enumerate(sentence):\n",
    "                    if i == index:\n",
    "                        mix_sentence += [item]\n",
    "                    else:\n",
    "                        if item in uri_label:\n",
    "                            mix_sentence += uri_label[item]\n",
    "                        elif item.startswith('http://www.w3.org'):\n",
    "                            mix_sentence += [item.split('#')[1].lower()]\n",
    "                        else:\n",
    "                            mix_sentence += [item]\n",
    "                Mix_Doc.append(mix_sentence)\n",
    "        elif FLAGS.Mix_Type.lower() == 'random':\n",
    "            random_index = random.randint(0, len(sentence)-1)\n",
    "            mix_sentence = list()\n",
    "            for i, item in enumerate(sentence):\n",
    "                if i == random_index:\n",
    "                    mix_sentence += [item]\n",
    "                else:\n",
    "                    if item in uri_label:\n",
    "                        mix_sentence += uri_label[item]\n",
    "                    elif item.startswith('http://www.w3.org'):\n",
    "                        mix_sentence += [item.split('#')[1].lower()]\n",
    "                    else:\n",
    "                        mix_sentence += [item]\n",
    "            Mix_Doc.append(mix_sentence)\n",
    "\n",
    "    for sentence in axiom_sentences:\n",
    "        if FLAGS.Mix_Type.lower() == 'all':\n",
    "            for index in range(len(sentence)):\n",
    "                random_index = random.randint(0, len(sentence) - 1)\n",
    "                mix_sentence = list()\n",
    "                for i, item in enumerate(sentence):\n",
    "                    if i == random_index:\n",
    "                        mix_sentence += [item]\n",
    "                    else:\n",
    "                        mix_sentence += uri_label[item] if item in uri_label else [item.lower()]\n",
    "                Mix_Doc.append(mix_sentence)\n",
    "        elif FLAGS.Mix_Type.lower() == 'random':\n",
    "            random_index = random.randint(0, len(sentence)-1)\n",
    "            mix_sentence = list()\n",
    "            for i, item in enumerate(sentence):\n",
    "                if i == random_index:\n",
    "                    mix_sentence += [item]\n",
    "                else:\n",
    "                    mix_sentence += uri_label[item] if item in uri_label else [item.lower()]\n",
    "            Mix_Doc.append(mix_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URI_Doc: 2253039, Lit_Doc: 0, Mix_Doc: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('URI_Doc: %d, Lit_Doc: %d, Mix_Doc: %d' % (len(URI_Doc), len(Lit_Doc), len(Mix_Doc)))\n",
    "all_doc = URI_Doc + Lit_Doc + Mix_Doc\n",
    "random.shuffle(all_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://purl.obolibrary.org/obo/FOODON_03305399</td>\n",
       "      <td>http://purl.obolibrary.org/obo/IAO_0000114</td>\n",
       "      <td>b'u\\x1a\\xbeX\\\\\\xec\\x85\\x96\\xec9D\\x05\\xa2)q\\x9d'</td>\n",
       "      <td>http://purl.obolibrary.org/obo/IAO_0000114</td>\n",
       "      <td>b\"\\xa9\\x16\\xbd\\x01\\x97:\\x1f\\xb5$ n\\xe1q't\\x04\"</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://purl.obolibrary.org/obo/FOODON_03542476</td>\n",
       "      <td>http://purl.obolibrary.org/obo/IAO_0000114</td>\n",
       "      <td>b'F\\xfbpd\\xe9 =\\xc9\\r*\\xf6\\xdc\\xce5Q/'</td>\n",
       "      <td>http://purl.obolibrary.org/obo/IAO_0000114</td>\n",
       "      <td>b'P\\x06\\x97\\xac\\xa2\\xa98E\\tp\\xf7h\\xaf\\xc0\\xa5\\...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://purl.obolibrary.org/obo/FOODON_03414141</td>\n",
       "      <td>http://www.geneontology.org/formats/oboInOwl#h...</td>\n",
       "      <td>b'\\x0f0M\\x17_=\\x1da\\xa3\\xdd\\xec\\x919(~\\x19'</td>\n",
       "      <td>http://www.geneontology.org/formats/oboInOwl#h...</td>\n",
       "      <td>b'm\\xf3\\xeb\\x01\\xca\\x0b\\xf4\\xb03\\x13a!l\\xe5\\xa...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://purl.obolibrary.org/obo/FOODON_03400829</td>\n",
       "      <td>http://www.w3.org/1999/02/22-rdf-syntax-ns#type</td>\n",
       "      <td>b'\\xcdy\\xf2\\x1dr\\x89(X+\\xbd \\xa2!\\xd4&gt;Q'</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://purl.obolibrary.org/obo/FOODON_03315876</td>\n",
       "      <td>http://www.w3.org/2000/01/rdf-schema#subClassOf</td>\n",
       "      <td>http://purl.obolibrary.org/obo/FOODON_00002007</td>\n",
       "      <td>http://www.w3.org/2000/01/rdf-schema#subClassOf</td>\n",
       "      <td>http://purl.obolibrary.org/obo/FOODON_00001792</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2253034</th>\n",
       "      <td>http://purl.obolibrary.org/obo/FOODON_03303025</td>\n",
       "      <td>SubClassOf</td>\n",
       "      <td>http://purl.obolibrary.org/obo/RO_0001000</td>\n",
       "      <td>some</td>\n",
       "      <td>http://purl.obolibrary.org/obo/FOODON_03411457</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2253035</th>\n",
       "      <td>http://purl.obolibrary.org/obo/FOODON_03303025</td>\n",
       "      <td>SubClassOf</td>\n",
       "      <td>http://purl.obolibrary.org/obo/RO_0002350</td>\n",
       "      <td>some</td>\n",
       "      <td>http://purl.obolibrary.org/obo/FOODON_03400212</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2253036</th>\n",
       "      <td>http://purl.obolibrary.org/obo/FOODON_03413352</td>\n",
       "      <td>EquivalentTo</td>\n",
       "      <td>http://purl.obolibrary.org/obo/FOODON_00001303</td>\n",
       "      <td>some</td>\n",
       "      <td>http://purl.obolibrary.org/obo/NCBITaxon_394708</td>\n",
       "      <td>and</td>\n",
       "      <td>http://purl.obolibrary.org/obo/FOODON_00001303</td>\n",
       "      <td>only</td>\n",
       "      <td>http://purl.obolibrary.org/obo/NCBITaxon_394708</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2253037</th>\n",
       "      <td>http://purl.obolibrary.org/obo/FOODON_03413352</td>\n",
       "      <td>SubClassOf</td>\n",
       "      <td>http://purl.obolibrary.org/obo/FOODON_03411084</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2253038</th>\n",
       "      <td>http://purl.obolibrary.org/obo/NCBITaxon_241778</td>\n",
       "      <td>SubClassOf</td>\n",
       "      <td>http://purl.obolibrary.org/obo/NCBITaxon_4037</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2253039 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0   \\\n",
       "0         http://purl.obolibrary.org/obo/FOODON_03305399   \n",
       "1         http://purl.obolibrary.org/obo/FOODON_03542476   \n",
       "2         http://purl.obolibrary.org/obo/FOODON_03414141   \n",
       "3         http://purl.obolibrary.org/obo/FOODON_03400829   \n",
       "4         http://purl.obolibrary.org/obo/FOODON_03315876   \n",
       "...                                                  ...   \n",
       "2253034   http://purl.obolibrary.org/obo/FOODON_03303025   \n",
       "2253035   http://purl.obolibrary.org/obo/FOODON_03303025   \n",
       "2253036   http://purl.obolibrary.org/obo/FOODON_03413352   \n",
       "2253037   http://purl.obolibrary.org/obo/FOODON_03413352   \n",
       "2253038  http://purl.obolibrary.org/obo/NCBITaxon_241778   \n",
       "\n",
       "                                                        1   \\\n",
       "0               http://purl.obolibrary.org/obo/IAO_0000114   \n",
       "1               http://purl.obolibrary.org/obo/IAO_0000114   \n",
       "2        http://www.geneontology.org/formats/oboInOwl#h...   \n",
       "3          http://www.w3.org/1999/02/22-rdf-syntax-ns#type   \n",
       "4          http://www.w3.org/2000/01/rdf-schema#subClassOf   \n",
       "...                                                    ...   \n",
       "2253034                                         SubClassOf   \n",
       "2253035                                         SubClassOf   \n",
       "2253036                                       EquivalentTo   \n",
       "2253037                                         SubClassOf   \n",
       "2253038                                         SubClassOf   \n",
       "\n",
       "                                                      2   \\\n",
       "0        b'u\\x1a\\xbeX\\\\\\xec\\x85\\x96\\xec9D\\x05\\xa2)q\\x9d'   \n",
       "1                 b'F\\xfbpd\\xe9 =\\xc9\\r*\\xf6\\xdc\\xce5Q/'   \n",
       "2            b'\\x0f0M\\x17_=\\x1da\\xa3\\xdd\\xec\\x919(~\\x19'   \n",
       "3               b'\\xcdy\\xf2\\x1dr\\x89(X+\\xbd \\xa2!\\xd4>Q'   \n",
       "4         http://purl.obolibrary.org/obo/FOODON_00002007   \n",
       "...                                                  ...   \n",
       "2253034        http://purl.obolibrary.org/obo/RO_0001000   \n",
       "2253035        http://purl.obolibrary.org/obo/RO_0002350   \n",
       "2253036   http://purl.obolibrary.org/obo/FOODON_00001303   \n",
       "2253037   http://purl.obolibrary.org/obo/FOODON_03411084   \n",
       "2253038    http://purl.obolibrary.org/obo/NCBITaxon_4037   \n",
       "\n",
       "                                                        3   \\\n",
       "0               http://purl.obolibrary.org/obo/IAO_0000114   \n",
       "1               http://purl.obolibrary.org/obo/IAO_0000114   \n",
       "2        http://www.geneontology.org/formats/oboInOwl#h...   \n",
       "3                                                     None   \n",
       "4          http://www.w3.org/2000/01/rdf-schema#subClassOf   \n",
       "...                                                    ...   \n",
       "2253034                                               some   \n",
       "2253035                                               some   \n",
       "2253036                                               some   \n",
       "2253037                                               None   \n",
       "2253038                                               None   \n",
       "\n",
       "                                                        4     5   \\\n",
       "0           b\"\\xa9\\x16\\xbd\\x01\\x97:\\x1f\\xb5$ n\\xe1q't\\x04\"  None   \n",
       "1        b'P\\x06\\x97\\xac\\xa2\\xa98E\\tp\\xf7h\\xaf\\xc0\\xa5\\...  None   \n",
       "2        b'm\\xf3\\xeb\\x01\\xca\\x0b\\xf4\\xb03\\x13a!l\\xe5\\xa...  None   \n",
       "3                                                     None  None   \n",
       "4           http://purl.obolibrary.org/obo/FOODON_00001792  None   \n",
       "...                                                    ...   ...   \n",
       "2253034     http://purl.obolibrary.org/obo/FOODON_03411457  None   \n",
       "2253035     http://purl.obolibrary.org/obo/FOODON_03400212  None   \n",
       "2253036    http://purl.obolibrary.org/obo/NCBITaxon_394708   and   \n",
       "2253037                                               None  None   \n",
       "2253038                                               None  None   \n",
       "\n",
       "                                                     6     7   \\\n",
       "0                                                  None  None   \n",
       "1                                                  None  None   \n",
       "2                                                  None  None   \n",
       "3                                                  None  None   \n",
       "4                                                  None  None   \n",
       "...                                                 ...   ...   \n",
       "2253034                                            None  None   \n",
       "2253035                                            None  None   \n",
       "2253036  http://purl.obolibrary.org/obo/FOODON_00001303  only   \n",
       "2253037                                            None  None   \n",
       "2253038                                            None  None   \n",
       "\n",
       "                                                      8     9   ...    15  \\\n",
       "0                                                   None  None  ...  None   \n",
       "1                                                   None  None  ...  None   \n",
       "2                                                   None  None  ...  None   \n",
       "3                                                   None  None  ...  None   \n",
       "4                                                   None  None  ...  None   \n",
       "...                                                  ...   ...  ...   ...   \n",
       "2253034                                             None  None  ...  None   \n",
       "2253035                                             None  None  ...  None   \n",
       "2253036  http://purl.obolibrary.org/obo/NCBITaxon_394708  None  ...  None   \n",
       "2253037                                             None  None  ...  None   \n",
       "2253038                                             None  None  ...  None   \n",
       "\n",
       "           16    17    18    19    20    21    22    23    24  \n",
       "0        None  None  None  None  None  None  None  None  None  \n",
       "1        None  None  None  None  None  None  None  None  None  \n",
       "2        None  None  None  None  None  None  None  None  None  \n",
       "3        None  None  None  None  None  None  None  None  None  \n",
       "4        None  None  None  None  None  None  None  None  None  \n",
       "...       ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "2253034  None  None  None  None  None  None  None  None  None  \n",
       "2253035  None  None  None  None  None  None  None  None  None  \n",
       "2253036  None  None  None  None  None  None  None  None  None  \n",
       "2253037  None  None  None  None  None  None  None  None  None  \n",
       "2253038  None  None  None  None  None  None  None  None  None  \n",
       "\n",
       "[2253039 rows x 25 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(URI_Doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame([t[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m Mix_Doc \u001b[38;5;28;01mif\u001b[39;00m t[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://www.w3.org/1999/02/22-rdf-syntax-ns#type\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "Cell \u001b[1;32mIn[67], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame([t[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m Mix_Doc \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://www.w3.org/1999/02/22-rdf-syntax-ns#type\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "pd.DataFrame([t[2] for t in URI_Doc if t[1] == \"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\"]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ = gensim.models.Word2Vec(all_doc, vector_size=FLAGS.embedsize, window=5, workers=multiprocessing.cpu_count(),\n",
    "                                    sg=1, epochs=10, negative=25, min_count=1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes.extend([\"http://www.w3.org/2002/07/owl#Class\", \"http://www.w3.org/2002/07/owl#ObjectProperty\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classes_e = embed(model=model_, instances=classes)\n",
    "new_embedsize = classes_e[0].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(classes_e).to_csv(r'D:\\.VScode\\projects\\Owls2Vec_star\\Workspace\\TTL\\OWL2VEC.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_e = pd.read_csv(r'D:\\.VScode\\projects\\Owls2Vec_star\\Workspace\\TTL\\OWL2VEC.csv', header=None).to_numpy()\n",
    "new_embedsize = classes_e[0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = [line.strip().split(',') for line in open(FLAGS.train_file).readlines()]\n",
    "valid_samples = [line.strip().split(',') for line in open(FLAGS.valid_file).readlines()]\n",
    "test_samples = [line.strip().split(',') for line in open(FLAGS.test_file).readlines()]\n",
    "random.shuffle(train_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/41688 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41688/41688 [00:20<00:00, 2080.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X: (26279, 200), train_y: (26279,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_x_list, train_y_list = list(), list()\n",
    "for s in tqdm(train_samples):\n",
    "    sub, sup, label = s[0], s[1], s[2]\n",
    "    sub_v = classes_e[classes.index(sub)]\n",
    "    sup_v = classes_e[classes.index(sup)]\n",
    "    if not (np.all(sub_v == 0) or np.all(sup_v == 0)):\n",
    "        if FLAGS.input_type == 'concatenate':\n",
    "            train_x_list.append(np.concatenate((sub_v, sup_v)))\n",
    "        else:\n",
    "            train_x_list.append(sub_v - sup_v)\n",
    "        train_y_list.append(int(label))\n",
    "train_X, train_y = np.array(train_x_list), np.array(train_y_list)\n",
    "print('train_X: %s, train_y: %s' % (str(train_X.shape), str(train_y.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_ancestors = dict()\n",
    "with open(FLAGS.inferred_ancestor_file) as f:\n",
    "    for line in f.readlines():\n",
    "        all_infer_classes = line.strip().split(',')\n",
    "        cls = all_infer_classes[0]\n",
    "        inferred_ancestors[cls] = all_infer_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InclusionEvaluator(Evaluator):\n",
    "    def __init__(self, valid_samples, test_samples, train_X, train_y):\n",
    "        super(InclusionEvaluator, self).__init__(valid_samples, test_samples, train_X, train_y)\n",
    "\n",
    "    def evaluate(self, model, eva_samples, mem_limit_GiB = 5):\n",
    "        print('Evaluating...')\n",
    "        sample_mem_size = 1_000_000_000 * 8 / (32 * candidate_num * train_X.shape[1])\n",
    "        array_size_limit = int(mem_limit_GiB * sample_mem_size)\n",
    "        if array_size_limit < 1:\n",
    "            raise ValueError(f'Memory limit is too small! at least {1/sample_mem_size:.3f} GiB is required.')\n",
    "        else:\n",
    "            print(f'Array size limit: {array_size_limit}')\n",
    "        MRR_sum, hits1_sum, hits5_sum, hits10_sum = 0, 0, 0, 0\n",
    "        arange = tqdm(range(0, len(eva_samples), array_size_limit), desc='Evaluating...')\n",
    "        accumulate_total = 0\n",
    "        for i in arange:\n",
    "            sub_eva_samples = eva_samples[i:i + array_size_limit]\n",
    "            X_array = np.empty((len(sub_eva_samples), candidate_num, train_X.shape[1]), dtype=np.float32)\n",
    "            for index, (individual, gt) in enumerate(sub_eva_samples):\n",
    "                sub_index = classes.index(sub)\n",
    "                sub_v = classes_e[sub_index]\n",
    "                X_array[index] = np.concatenate((np.array([sub_v] * candidate_num), classes_e), axis=1)\n",
    "                \n",
    "            predicted_proba_array = X_array.reshape(-1, train_X.shape[1])\n",
    "            predicted_proba_array = model.predict_proba(predicted_proba_array)[:, 1].reshape((len(sub_eva_samples), candidate_num))\n",
    "            \n",
    "            for P, (individual, gt) in zip(predicted_proba_array, sub_eva_samples):\n",
    "                sorted_indexes = np.argsort(P)[::-1]\n",
    "                sorted_classes = list()\n",
    "                for j in sorted_indexes:\n",
    "                    if classes[j] not in inferred_ancestors[individual]:\n",
    "                        sorted_classes.append(classes[j])\n",
    "                rank = sorted_classes.index(gt) + 1\n",
    "                MRR_sum += 1.0 / rank\n",
    "                hits1_sum += 1 if gt in sorted_classes[:1] else 0\n",
    "                hits5_sum += 1 if gt in sorted_classes[:5] else 0\n",
    "                hits10_sum += 1 if gt in sorted_classes[:10] else 0\n",
    "                \n",
    "            accumulate_total += len(sub_eva_samples)\n",
    "            e_MRR, hits1, hits5, hits10 = MRR_sum / accumulate_total, hits1_sum / accumulate_total, hits5_sum / accumulate_total, hits10_sum / accumulate_total\n",
    "            desc = f'({accumulate_total}) Evaluated MRR {e_MRR:.3f}, Hits@1 {hits1:.3f}, Hits@5 {hits5:.3f}, Hits@10 {hits10:.3f}'\n",
    "            arange.set_description(desc)\n",
    "        return e_MRR, hits1, hits5, hits10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\t2.Train and test ... \n",
      "\n",
      "Evaluating...\n",
      "Array size limit: 221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluated MRR 0.003, Hits@1 0.000, Hits@5 0.003, Hits@10 0.005:  11%|█         | 3/27 [10:22<1:23:03, 207.66s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\t\t2.Train and test ... \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m InclusionEvaluator(valid_samples, test_samples, train_X, train_y)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_random_forest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\.VScode\\projects\\Owls2Vec_star\\OWL2Vec-Star-master\\OWL2Vec-Star-master\\case_studies\\foodon_subsumption\\owl2vec_star\\lib\\Evaluator.py:28\u001b[0m, in \u001b[0;36mEvaluator.run_random_forest\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     26\u001b[0m rf\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_y)\n\u001b[0;32m     27\u001b[0m rf_best \u001b[38;5;241m=\u001b[39m rf\n\u001b[1;32m---> 28\u001b[0m MRR, hits1, hits5, hits10 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrf_best\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meva_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTesting, MRR: \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m, Hits@1: \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m, Hits@5: \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m, Hits@10: \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (MRR, hits1, hits5, hits10))\n",
      "Cell \u001b[1;32mIn[34], line 25\u001b[0m, in \u001b[0;36mInclusionEvaluator.evaluate\u001b[1;34m(self, model, eva_samples, mem_limit_GiB)\u001b[0m\n\u001b[0;32m     22\u001b[0m     X_array[index] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((np\u001b[38;5;241m.\u001b[39marray([sub_v] \u001b[38;5;241m*\u001b[39m candidate_num), classes_e), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     24\u001b[0m predicted_proba_array \u001b[38;5;241m=\u001b[39m X_array\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, train_X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 25\u001b[0m predicted_proba_array \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted_proba_array\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;28mlen\u001b[39m(sub_eva_samples), candidate_num))\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m P, (individual, gt) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(predicted_proba_array, sub_eva_samples):\n\u001b[0;32m     28\u001b[0m     sorted_indexes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(P)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32md:\\.VScode\\projects\\Owls2Vec_star\\.conda\\lib\\site-packages\\scikit_learn-0.24.2-py3.8-win-amd64.egg\\sklearn\\ensemble\\_forest.py:683\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    680\u001b[0m all_proba \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mzeros((X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], j), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    681\u001b[0m              \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39matleast_1d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_)]\n\u001b[0;32m    682\u001b[0m lock \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mLock()\n\u001b[1;32m--> 683\u001b[0m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_joblib_parallel_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequire\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msharedmem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_accumulate_prediction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_proba\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimators_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m proba \u001b[38;5;129;01min\u001b[39;00m all_proba:\n\u001b[0;32m    690\u001b[0m     proba \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_)\n",
      "File \u001b[1;32md:\\.VScode\\projects\\Owls2Vec_star\\.conda\\lib\\site-packages\\joblib-1.3.2-py3.8.egg\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32md:\\.VScode\\projects\\Owls2Vec_star\\.conda\\lib\\site-packages\\joblib-1.3.2-py3.8.egg\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32md:\\.VScode\\projects\\Owls2Vec_star\\.conda\\lib\\site-packages\\scikit_learn-0.24.2-py3.8-win-amd64.egg\\sklearn\\utils\\fixes.py:222\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 222\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\.VScode\\projects\\Owls2Vec_star\\.conda\\lib\\site-packages\\scikit_learn-0.24.2-py3.8-win-amd64.egg\\sklearn\\ensemble\\_forest.py:467\u001b[0m, in \u001b[0;36m_accumulate_prediction\u001b[1;34m(predict, X, out, lock)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_accumulate_prediction\u001b[39m(predict, X, out, lock):\n\u001b[0;32m    461\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;124;03m    This is a utility function for joblib's Parallel.\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \n\u001b[0;32m    464\u001b[0m \u001b[38;5;124;03m    It can't go locally in ForestClassifier or ForestRegressor, because joblib\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03m    complains that it cannot pickle it when placed there.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 467\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m lock:\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32md:\\.VScode\\projects\\Owls2Vec_star\\.conda\\lib\\site-packages\\scikit_learn-0.24.2-py3.8-win-amd64.egg\\sklearn\\tree\\_classes.py:936\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.predict_proba\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    934\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    935\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X, check_input)\n\u001b[1;32m--> 936\u001b[0m proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    939\u001b[0m     proba \u001b[38;5;241m=\u001b[39m proba[:, :\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"\\n\t\t2.Train and test ... \\n\")\n",
    "evaluator = InclusionEvaluator(valid_samples, test_samples, train_X, train_y)\n",
    "evaluator.run_random_forest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concept2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = r\"D:\\.VScode\\projects\\Owls2Vec_star\\Workspace\\TTL\\KGE_data\\FoodOn\\train_dataset.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mConceptClass\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, concept, concept_embedded_vector, entities, entities_embedded_vectors):\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcept \u001b[38;5;241m=\u001b[39m concept\n",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m, in \u001b[0;36mConceptClass\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentities_embedded_vectors \u001b[38;5;241m=\u001b[39m entities_embedded_vectors\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage_entities_vectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage_entities_vectors()\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconcept: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcept\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity\u001b[39m(\u001b[38;5;28mself\u001b[39m, vec1, vec2):\n",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m, in \u001b[0;36mConceptClass\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentities_embedded_vectors \u001b[38;5;241m=\u001b[39m entities_embedded_vectors\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage_entities_vectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage_entities_vectors()\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconcept: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcept\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity\u001b[39m(\u001b[38;5;28mself\u001b[39m, vec1, vec2):\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1395\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1344\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\.VScode\\projects\\Owls2Vec_star\\.conda\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32md:\\.VScode\\projects\\Owls2Vec_star\\.conda\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class ConceptClass:\n",
    "    def __init__(self, concept, concept_embedded_vector, entities, entities_embedded_vectors):\n",
    "        self.concept = concept\n",
    "        self.concept_embedded_vector = concept_embedded_vector\n",
    "        self.entities = entities \n",
    "        self.entities_embedded_vectors = entities_embedded_vectors\n",
    "\n",
    "        self.average_entities_vectors = self.average_entities_vectors()\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'concept: {self.concept}'\n",
    "    \n",
    "    def similarity(self, vec1, vec2):\n",
    "        return np.dot(vec1,vec2)/(np.linalg.norm(vec1)*np.linalg.norm(vec2))\n",
    "    \n",
    "    def coherence_score(self, res_concepts, target_concept):\n",
    "        return sum(res_concepts == target_concept) / res_concepts.shape[0]\n",
    "    \n",
    "    def average_entities_vectors(self):\n",
    "        return np.mean(self.entities_embedded_vectors, axis = 0)\n",
    "    \n",
    "class OntologyEvaluation:\n",
    "    def __init__(self, triples, entity_to_id, embedded_vectors, type_relations = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#type'):\n",
    "        self.type_relations = triples[(triples.iloc[:,1] == type_relations)]\n",
    "        self.entity_to_id = entity_to_id\n",
    "        self.embedded_vector = embedded_vectors\n",
    "        \n",
    "        self.concepts = self.filter_concepts_from_triples()\n",
    "        self.concat_df = self.create_concat_embedded_vectors()\n",
    "\n",
    "    def create_concat_embedded_vectors(self):\n",
    "        concat_df = []\n",
    "        for concept in self.concepts:\n",
    "            _df = pd.DataFrame({'vector': [i for i in concept.entities_embedded_vectors]})\n",
    "            _df['label'] = concept.concept\n",
    "            concat_df.append(_df)\n",
    "        concat_df = pd.concat(concat_df, axis=0).reset_index(drop=True)\n",
    "        return concat_df\n",
    "        \n",
    "    def filter_concepts_from_triples(self, filter_num = 1):\n",
    "        concepts_count = pd.DataFrame(self.type_relations.iloc[:, 2]).value_counts(sort = True)\n",
    "        evalution_concepts = concepts_count[concepts_count > filter_num]\n",
    "        print(evalution_concepts)\n",
    "        \n",
    "        filter_concepts = evalution_concepts.index.to_list()\n",
    "        for i, concept in enumerate(filter_concepts):\n",
    "            concept = concept[0]\n",
    "            concept_embedded_vector = self.get_embedded_vectors_from_label(concept)\n",
    "            \n",
    "            entities = self.get_entities_from_concept(concept)\n",
    "            entities_embedded_vector = self.get_embedded_vectors_from_labels(entities)\n",
    "            \n",
    "            filter_concepts[i] = ConceptClass(concept, concept_embedded_vector, entities, entities_embedded_vector)\n",
    "            \n",
    "        return filter_concepts\n",
    "    \n",
    "    def get_entities_from_concept(self, concept):\n",
    "        entities = self.type_relations[self.type_relations.iloc[:,2] == concept].iloc[:,0]\n",
    "        return entities\n",
    "    \n",
    "    def get_embedded_vectors_from_label(self, label):\n",
    "        #Get index from label\n",
    "        index = self.entity_to_id[label]\n",
    "        \n",
    "        #Get embedded vector from index\n",
    "        concept_embedded_vector = self.embedded_vector[index]\n",
    "        return concept_embedded_vector\n",
    "    \n",
    "    def get_embedded_vectors_from_labels(self, labels):\n",
    "        concept_embedded_vectors = []\n",
    "        for label in labels:\n",
    "            concept_embedded_vectors.append(self.get_embedded_vectors_from_label(label))\n",
    "        return np.array(concept_embedded_vectors)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SIREN DB annotation:\\n* has quality 'semisolid...</td>\n",
       "      <td>http://www.w3.org/2002/07/owl#sameAs</td>\n",
       "      <td>SIREN DB annotation:\\n* has quality 'semisolid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anabantoidei</td>\n",
       "      <td>http://www.w3.org/2002/07/owl#sameAs</td>\n",
       "      <td>Anabantoidei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://purl.obolibrary.org/obo/UO_0000113</td>\n",
       "      <td>http://www.w3.org/1999/02/22-rdf-syntax-ns#type</td>\n",
       "      <td>http://www.w3.org/2002/07/owl#Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://purl.obolibrary.org/obo/FOODON_03307105</td>\n",
       "      <td>http://www.w3.org/2000/01/rdf-schema#comment</td>\n",
       "      <td>SIREN DB annotation:\\n* has quality 'whole, sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://purl.obolibrary.org/obo/FOODON_03316729</td>\n",
       "      <td>http://www.w3.org/2000/01/rdf-schema#comment</td>\n",
       "      <td>SIREN DB annotation:\\n* surrounded by 'can, bo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                head  \\\n",
       "0  SIREN DB annotation:\\n* has quality 'semisolid...   \n",
       "1                                       Anabantoidei   \n",
       "2          http://purl.obolibrary.org/obo/UO_0000113   \n",
       "3     http://purl.obolibrary.org/obo/FOODON_03307105   \n",
       "4     http://purl.obolibrary.org/obo/FOODON_03316729   \n",
       "\n",
       "                                          relation  \\\n",
       "0             http://www.w3.org/2002/07/owl#sameAs   \n",
       "1             http://www.w3.org/2002/07/owl#sameAs   \n",
       "2  http://www.w3.org/1999/02/22-rdf-syntax-ns#type   \n",
       "3     http://www.w3.org/2000/01/rdf-schema#comment   \n",
       "4     http://www.w3.org/2000/01/rdf-schema#comment   \n",
       "\n",
       "                                                tail  \n",
       "0  SIREN DB annotation:\\n* has quality 'semisolid...  \n",
       "1                                       Anabantoidei  \n",
       "2                http://www.w3.org/2002/07/owl#Class  \n",
       "3  SIREN DB annotation:\\n* has quality 'whole, sh...  \n",
       "4  SIREN DB annotation:\\n* surrounded by 'can, bo...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triples = pd.read_csv(TRAIN_PATH, header=None, names=['head', 'relation', 'tail'])\n",
    "triples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_dict = {cls: i for i, cls in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tail                                        \n",
      "http://www.w3.org/2002/07/owl#Class             28182\n",
      "http://www.w3.org/2002/07/owl#ObjectProperty       56\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'http://www.w3.org/2002/07/owl#Class'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m evalution_concepts \u001b[38;5;241m=\u001b[39m \u001b[43mOntologyEvaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtriples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses_e\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[30], line 28\u001b[0m, in \u001b[0;36mOntologyEvaluation.__init__\u001b[1;34m(self, triples, entity_to_id, embedded_vectors, type_relations)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentity_to_id \u001b[38;5;241m=\u001b[39m entity_to_id\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedded_vector \u001b[38;5;241m=\u001b[39m embedded_vectors\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcepts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_concepts_from_triples\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcat_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_concat_embedded_vectors()\n",
      "Cell \u001b[1;32mIn[30], line 48\u001b[0m, in \u001b[0;36mOntologyEvaluation.filter_concepts_from_triples\u001b[1;34m(self, filter_num)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, concept \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(filter_concepts):\n\u001b[0;32m     47\u001b[0m     concept \u001b[38;5;241m=\u001b[39m concept[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 48\u001b[0m     concept_embedded_vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_embedded_vectors_from_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcept\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     entities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_entities_from_concept(concept)\n\u001b[0;32m     51\u001b[0m     entities_embedded_vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_embedded_vectors_from_labels(entities)\n",
      "Cell \u001b[1;32mIn[30], line 63\u001b[0m, in \u001b[0;36mOntologyEvaluation.get_embedded_vectors_from_label\u001b[1;34m(self, label)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_embedded_vectors_from_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label):\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m#Get index from label\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentity_to_id\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m#Get embedded vector from index\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     concept_embedded_vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedded_vector[index]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'http://www.w3.org/2002/07/owl#Class'"
     ]
    }
   ],
   "source": [
    "evalution_concepts = OntologyEvaluation(triples, classes_dict, classes_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in evalution_concepts.concepts:\n",
    "    print(f'{task.concept: <35}: {task.similarity(task.concept_embedded_vector, task.average_entities_vectors):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 10\n",
    "concat_df = evalution_concepts.concat_df\n",
    "for task in evalution_concepts.concepts:\n",
    "\n",
    "    res_sims = concat_df.iloc[:, 0].map(lambda x: task.similarity(x, task.concept_embedded_vector)).sort_values(ascending=False).head(top_k)\n",
    "    res_concepts = concat_df['label'].loc[res_sims.index]\n",
    "    res_score = task.coherence_score(res_concepts, task.concept)\n",
    "    print(f'{task.concept: <35}: {res_score:.3f} | {task.entities.shape[0] / concat_df.shape[0]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance in the embedding space of training samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulate_distances = np.zeros((2))\n",
    "count = 0\n",
    "for s in tqdm(train_samples):\n",
    "    ind, cls, label = s[0], s[1], s[2]\n",
    "    ind_v = classes_e[classes.index(ind)]\n",
    "    cls_v = classes_e[classes.index(cls)]\n",
    "    if not (np.all(ind_v == 0) or np.all(cls_v == 0)):\n",
    "        dist_ind = int(label)\n",
    "        accumulate_distances[dist_ind] += np.linalg.norm(ind_v - cls_v)\n",
    "        count += 1\n",
    "average_distance = accumulate_distances / count\n",
    "ratio = average_distance[1] / average_distance[0]\n",
    "print('average_distance:\\nfor positive: {:.3f}\\nfor negative: {:.3f}\\nfor ratio {:.3f}'.format(average_distance[1], average_distance[0], ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-SNE visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% pip install seaborn matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples_df = pd.DataFrame(train_samples, columns=['individual', 'class', 'label'])\n",
    "positive_samples_df = train_samples_df[train_samples_df['label'] == '1'].drop(columns=['label'])\n",
    "positive_samples_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot(X_embedded, combined_label, class_labels, color_list, label = ''):\n",
    "    plt.clf()\n",
    "    for label_i, (x, y), color in zip(combined_label, X_embedded, color_list):\n",
    "        plt.plot(x, y, 'o', c = sns.color_palette()[color])\n",
    "        if label_i in class_labels:\n",
    "            plt.text(x * (1.02), y * (1.02) , label_i, fontsize=10)\n",
    "\n",
    "    if label != '':\n",
    "        plt.title(label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_classes = []\n",
    "tsne_X_label = []\n",
    "combined_data = []\n",
    "tsne_class_label = []\n",
    "clean = lambda x: x.split('#')[-1] \n",
    "\n",
    "\n",
    "for i, cls in enumerate(tsne_classes, 1):\n",
    "    samples = positive_samples_df.loc[positive_samples_df[\"class\"] == cls, \"individual\"]\n",
    "    \n",
    "    tsne_X_label.append(cls)\n",
    "    tsne_X_label.extend(samples)\n",
    "    \n",
    "    tsne_class_label.extend([0] + [i] * (len(samples)))\n",
    "    \n",
    "    cls_v = classes_e[classes.index(cls)]\n",
    "    combined_data.append(cls_v)\n",
    "    for sample in samples:\n",
    "        ind_v = classes_e[classes.index(sample)]\n",
    "        combined_data.append(ind_v)\n",
    "\n",
    "combined_data = np.array(combined_data)\n",
    "tsne_X_label = [clean(l) for l in tsne_X_label]\n",
    "tsne_classes_clean = [clean(l) for l in tsne_classes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded = TSNE(n_components=2, n_jobs = -1, early_exaggeration= 20).fit_transform(combined_data)\n",
    "\n",
    "_plot(X_embedded, tsne_X_label, tsne_classes_clean, tsne_class_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class-entity experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_classes = positive_samples_df[\"class\"].unique().tolist()  \n",
    "tsne_classes_emgedded = [classes_e[classes.index(cls)] for cls in tsne_classes]\n",
    "\n",
    "tsne_entity = positive_samples_df[\"individual\"].sample(1000, replace=False).tolist()\n",
    "tsne_entity_embedded = [classes_e[classes.index(ind)] for ind in tsne_entity]\n",
    "\n",
    "combined_data = tsne_classes_emgedded + tsne_entity_embedded\n",
    "combined_color = ['red'] * len(tsne_classes_emgedded) + ['grey'] * len(tsne_entity_embedded)\n",
    "combined_data = np.array(combined_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded = TSNE(n_components=2, n_jobs = -1, early_exaggeration= 20).fit_transform(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "for (x, y), color in zip(X_embedded, combined_color):\n",
    "    plt.plot(x, y, 'o', c = color)\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
